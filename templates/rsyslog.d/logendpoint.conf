module(load="impstats"
      interval="60"
      severity="7"
      log.syslog="off"
      log.file="/var/log/rsyslog_stats.log"
)

module(load="mmnormalize")

module(load="mmkubernetes"
       kubernetesurl="{{ openshift_master_public_api_url | default('https://' ~ openshift_master_cluster_public_hostname ~ ':443') }}"
       tls.cacert="/etc/rsyslog.d/mmk8s.ca.crt"
       tokenfile="/etc/rsyslog.d/mmk8s.token")

# JSON format for External Log Insight - Used for ordering structured data
template(name="ext-log-forwarding" type="list") {
       constant(value="<")                                              property(name="pri")
       constant(value=">")                                              property(name="timereported" dateFormat="rfc3164")
       constant(value=" ")                                              property(name=".clustername")
       constant(value=" ")                                              property(name=".containertag")
       constant(value=": { \"docker\": { \"container_id\": \"")         property(name="!docker!container_id")
       constant(value="\" }, \"kubernetes\": { \"namespace_name\": \"") property(name="!kubernetes!namespace_name")
       constant(value="\", \"pod_name\": \"")                           property(name="!kubernetes!pod_name")
       constant(value="\", \"labels\": ")                               property(name="!kubernetes!labels")
       constant(value=", \"namespace_labels\": ")                       property(name="!kubernetes!namespace_labels")
       constant(value=", \"host\": \"")                                 property(name="!kubernetes!host")
       constant(value="\", \"container_name\": \"")                     property(name="!kubernetes!container_name")
       constant(value="\", \"namespace_id\": \"")                       property(name="!kubernetes!namespace_id")
       constant(value="\", \"pod_id\": \"")                             property(name="!kubernetes!pod_id")
       constant(value="\", \"creation_timestamp\": \"")                 property(name="!kubernetes!creation_timestamp")
       constant(value="\" }, \"hostname\": \"")                         property(name="!kubernetes!host")
       constant(value="\", \"message\": \"")                            property(name=".message")
       constant(value="\", \"@timestamp\": \"")                         property(name=".writetime")
       constant(value="\" }\n")
}

# OBSOLETE - Previous JSON format for External Log Insight
# template(name="ext-log-forwarding" type="string"
#       string="<%PRI%>1 %TIMESTAMP:::date-rfc3164% %$.clustername% %$.containertag%: %$!all-json%\n")

# TimeStamp normalized
template(name="timereportedrfc3339" type="string"
      string="%timereported:::date-rfc3339%")

# Syslog format from fluentd
# syslogrelay ${record["kubernetes"]["host"]} ${record["kubernetes"]["namespace_name"]} ${record["kubernetes"]["pod_name"]} ${record["kubernetes"]["container_name"]} cmdb:${record["kubernetes"]["labels"]["cmdb"]} ${record["@timestamp"]} ${record["message"]}

main_queue(
      # Directory where the queue files on disk will be stored
      queue.spoolDirectory="/var/lib/rsyslog"
      # Prefix of the name the queue files on disk
      queue.filename="outp-queue"
      # In-memory linked-list queue, but because filename is defined it is disk-assisted
      # See http://www.rsyslog.com/doc/v8-stable/concepts/queues.html?highlight=disk%20assisted
      queue.type="linkedlist"
      # Only store up to 2 GB of logs on disk
      queue.maxdiskspace="2g"
      # Use 100 MB queue files
      queue.maxfilesize="100m"
      # Update disk queue every 1,000 messages
      queue.checkpointinterval="1000"
      # Fsync when a check point occurs
      queue.syncqueuefiles="on"
      # Allow up to 4 threads processing items in the queue
      queue.workerthreads="4"
      # Beef up the internal message queue
      queue.size="131072"
      # 75% of QueueSize, start persisting to disk
      queue.highwatermark="98304"
      # 90% of QueueSize, start discarding messages
      queue.discardmark="117964"
      # If we reach the discard mark, we'll throw out notice, info, and debug messages
      queue.discardseverity="5"
)

if ($!_SYSTEMD_UNIT == "atomic-openshift-master-api.service") or ($!_SYSTEMD_UNIT == "atomic-openshift-master-controllers.service") or ($!_SYSTEMD_UNIT == "atomic-openshift-node.service") then {
      action(type="omfile" name="openshift-services-log"
             Template="RSYSLOG_FileFormat"
             File="/var/log/atomic-openshift-services.log"
             # Compress file to gzip format
             zipLevel="9"
             asyncWriting="on"
             # Turn off flush to disk after every log line is handled, as it kills compression
             flushOnTXEnd="on"
             # Gives us a better chance of compression
             ioBufferSize="1024k"
             # Adds additional headers to the zip to reduce "invalid compressed data"
             veryRobustZip="on"
             # More of a chance to fill buffer to be compressed
             flushInterval="10")
      stop
}

# Check that log originated from Docker and is a container log, not an operational log
if ($!_SYSTEMD_UNIT == "docker.service") and (strlen($!CONTAINER_NAME) > 0) then {
      action(type="mmnormalize" name="router_parser" variable="msg" rulebase="/etc/rsyslog.d/router_parser.rb")
      # Check if router message should be dropped
      if strlen($!dropwarn) > 0 then {
        stop
      } else {
        unset $!originalmsg;
        unset $!unparsed-data;
      }

      action(type="mmkubernetes")

      action(type="mmnormalize" name="content_parser" variable="msg" rulebase="/etc/rsyslog.d/content_parser.rb")
      # Check if parsing failed, clean up
      if strlen($!originalmsg) > 0 then {
        set $.message = $msg;
        set $.writetime = exec_template("timereportedrfc3339");
        unset $!originalmsg;
        unset $!unparsed-data;
      } else if strlen($!payload!log) == 0 then {
      # Check if parsing was successful but did not result in a payload log field
        set $.message = $msg;
        set $.writetime = exec_template("timereportedrfc3339");
        unset $!originalmsg;
        unset $!unparsed-data;
        unset $!payload;
      } else {
        set $.message = $!payload!log;
        set $.writetime = $!payload!time;
        unset $!payload;
      }
      # Drop empty messages
      if strlen($.message) == 0 then {
        stop
      }

      # Parsing of JSON data
      set $.containertag = "ocp.{{ environ }}.container";
      set $.logeventtag = "ocp.{{ environ }}.logevent";
      set $.securityeventtag = "ocp.{{ environ }}.securityevent";
      set $.clustername = "{{ openshift_master_cluster_public_hostname }}";

      # Check if !namespace_labels!application is defined, else extract application from namespace name
      if strlen($!kubernetes!labels!application) == 0 then {
        if strlen($!kubernetes!namespace_labels!application) != 0 then {
          set $!kubernetes!labels!application = $!kubernetes!namespace_labels!application;
        } else {
          action(type="mmnormalize" name="namespace_parser" variable="$!kubernetes!namespace_name" rulebase="/etc/rsyslog.d/namespace_parser.rb")
          # Check if parsing failed, clean up
          if strlen($!originalmsg) > 0 then {
            unset $!originalmsg;
            unset $!unparsed-data;
          } else {
            unset $!foo;
          }
          set $!kubernetes!labels!application = $!application;
        }
      }

      if strlen($!kubernetes!labels!deploymentConfig) == 0 then {
        set $!kubernetes!labels!deploymentConfig = $!kubernetes!container_name;
      }
      if strlen($!kubernetes!labels!microservice) == 0 then {
        set $!kubernetes!labels!microservice = $!kubernetes!container_name;
      }

      unset $!metadata;
      unset $!PRIORITY;
      unset $!CONTAINER_ID;
      unset $!CONTAINER_ID_FULL;
      unset $!CONTAINER_NAME;
      unset $!CONTAINER_TAG;
      unset $!MESSAGE;
      unset $!_TRANSPORT;
      unset $!_PID;
      unset $!_UID;
      unset $!_GID;
      unset $!_COMM;
      unset $!_EXE;
      unset $!_CMDLINE;
      unset $!_CAP_EFFECTIVE;
      unset $!_SYSTEMD_CGROUP;
      unset $!_SYSTEMD_UNIT;
      unset $!_SYSTEMD_SLICE;
      unset $!_SELINUX_CONTEXT;
      unset $!_BOOT_ID;
      unset $!_MACHINE_ID;
      unset $!_HOSTNAME;
      unset $!_SOURCE_REALTIME_TIMESTAMP;

      action(type="omfwd" name="ext_log_endpoint" Template="ext-log-forwarding" Target="{{ ext_logging_endpoint }}" Port="514" Protocol="tcp"
        # Directory where the queue files on disk will be stored
        queue.spoolDirectory="/var/lib/rsyslog"
        # Prefix of the name the queue files on disk
        queue.filename="omfwd-queue"
        # In-memory linked-list queue, but because filename is defined it is disk-assisted
        # See http://www.rsyslog.com/doc/v8-stable/concepts/queues.html?highlight=disk%20assisted
        queue.type="linkedlist"
        # Only store up to 16 GB of logs on disk
        queue.maxdiskspace="16g"
        # Use 500 MB queue files
        queue.maxfilesize="500m"
        # Update disk queue every 1,000 messages
        queue.checkpointinterval="1000"
        # Fsync when a check point occurs
        queue.syncqueuefiles="on"
        # Allow up to 4 threads processing items in the queue
        queue.workerthreads="4"
        # Beef up the internal message queue
        queue.size="131072"
        # 75% of QueueSize, start persisting to disk
        queue.highwatermark="98304"
        # 90% of QueueSize, start discarding messages
        queue.discardmark="117964"
        # If we reach the discard mark, we'll throw out notice, info, and debug messages
        queue.discardseverity="5"
      )

      # Log to disk for debugging purposes only
      # action(type="omfile" Template="RSYSLOG_DebugFormat" File="/var/log/rsyslog-debug.log")
      stop
}
