module(load="impstats"
      interval="60"
      severity="7"
      log.syslog="off"
      log.file="/var/log/rsyslog_stats.log"
)

module(load="mmnormalize")

# JSON format for External Log Endpoint
template(name="ext-log-forwarding" type="string"
      string="<%PRI%>1 %TIMESTAMP:::date-rfc3164% %$.clustername% %$.containertag%: %$!all-json%\n")

# TimeStamp normalized
template(name="timereportedrfc3339" type="string"
      string="%timereported:::date-rfc3339%")

# Syslog format from fluentd)
# syslogrelay ${record["kubernetes"]["host"]} ${record["kubernetes"]["namespace_name"]} ${record["kubernetes"]["pod_name"]} ${record["kubernetes"]["container_name"]} cmdb:${record["kubernetes"]["labels"]["cmdb"]} ${record["@timestamp"]} ${record["message"]}

main_queue(
      # Directory where the queue files on disk will be stored
      queue.spoolDirectory="/var/lib/rsyslog"
      # Prefix of the name the queue files on disk
      queue.filename="outp-queue"
      # In-memory linked-list queue, but because filename is defined it is disk-assisted
      # See http://www.rsyslog.com/doc/v8-stable/concepts/queues.html?highlight=disk%20assisted
      queue.type="linkedlist"
      # Only store up to 2 GB of logs on disk
      queue.maxdiskspace="2g"
      # Use 100 MB queue files
      queue.maxfilesize="100m"
      # Update disk queue every 1,000 messages
      queue.checkpointinterval="1000"
      # Fsync when a check point occurs
      queue.syncqueuefiles="on"
      # Allow up to 4 threads processing items in the queue
      queue.workerthreads="4"
      # Beef up the internal message queue
      queue.size="131072"
      # 75% of QueueSize, start persisting to disk
      queue.highwatermark="98304"
      # 90% of QueueSize, start discarding messages
      queue.discardmark="117964"
      # If we reach the discard mark, we'll throw out notice, info, and debug messages
      queue.discardseverity="5"
)

if ($!_SYSTEMD_UNIT == "atomic-openshift-master-api.service") or ($!_SYSTEMD_UNIT == "atomic-openshift-master-controllers.service") or ($!_SYSTEMD_UNIT == "atomic-openshift-node.service") then {
      action(type="omfile" name="openshift-services-log"
             Template="RSYSLOG_FileFormat"
             File="/var/log/atomic-openshift-services.log"
             # Compress file to gzip format
             zipLevel="9"
             asyncWriting="on"
             # Turn off flush to disk after every log line is handled, as it kills compression
             flushOnTXEnd="on"
             # Gives us a better chance of compression
             ioBufferSize="1024k"
             # Adds additional headers to the zip to reduce "invalid compressed data"
             veryRobustZip="on"
             # More of a chance to fill buffer to be compressed
             flushInterval="10")
      stop
}

# Check that log originated from Docker and is a container log, not an operational log
if ($!_SYSTEMD_UNIT == "docker.service") and (strlen($!CONTAINER_NAME) > 0) then {
      action(type="mmnormalize" name="router_parser" variable="msg" rulebase="/etc/rsyslog.d/router_parser.rb")
      # Check if router message should be dropped
      if strlen($!dropwarn) > 0 then {
        stop
      } else {
        unset $!originalmsg;
        unset $!unparsed-data;
      }

      action(type="mmnormalize" name="container_parser" variable="$!CONTAINER_NAME" rulebase="/etc/rsyslog.d/containername_parser.rb")
      # Check if parsing failed, clean up
      if strlen($!originalmsg) > 0 then {
        unset $!originalmsg;
        unset $!unparsed-data;
      } else {
        unset $!foo;
      }

      action(type="mmnormalize" name="content_parser" variable="msg" rulebase="/etc/rsyslog.d/content_parser.rb")
      # Check if parsing failed, clean up
      if strlen($!originalmsg) > 0 then {
        set $.message = $msg;
        set $.writetime = exec_template("timereportedrfc3339");
        unset $!originalmsg;
        unset $!unparsed-data;
      } else if strlen($!payload!log) == 0 then {
      # Check if parsing was successful but did not result in a payload log field
        set $.message = $msg;
        set $.writetime = exec_template("timereportedrfc3339");
        unset $!originalmsg;
        unset $!unparsed-data;
        unset $!payload;
      } else {
        set $.message = $!payload!log;
        set $.writetime = $!payload!time;
        unset $!payload;
      }
      # Drop empty messages
      if strlen($.message) == 0 then {
        stop
      }

      action(type="mmnormalize" name="namespace_parser" variable="$!namespace_name" rulebase="/etc/rsyslog.d/namespace_parser.rb")
      # Check if parsing failed, clean up
      if strlen($!originalmsg) > 0 then {
        unset $!originalmsg;
        unset $!unparsed-data;
      } else {
        unset $!foo;
      }

      # Parsing of JSON data
      set $.containertag = "ocp.{{ environ }}.container";
      set $.logeventtag = "ocp.{{ environ }}.logevent";
      set $.securityeventtag = "ocp.{{ environ }}.securityevent";
      set $.clustername = "{{ openshift_master_cluster_public_hostname }}";
      set $!docker!container_id = $!CONTAINER_ID_FULL;
      set $!kubernetes!namespace_name = $!namespace_name;
      set $!kubernetes!pod_name = $!pod_name;
      set $!kubernetes!labels!application = $!application;
      set $!kubernetes!labels!deploymentConfig = $!service_name;
      set $!kubernetes!labels!microservice = $!service_name;
      set $!kubernetes!host = $!_HOSTNAME;
      set $!kubernetes!container_name = $!service_name;
      set $!hostname = $!_HOSTNAME;
      set $!message = $.message;
      set $!@timestamp = $.writetime;
      unset $!metadata;
      unset $!namespace_name;
      unset $!pod_name;
      unset $!application;
      unset $!service_name;
      unset $!PRIORITY;
      unset $!CONTAINER_ID;
      unset $!CONTAINER_ID_FULL;
      unset $!CONTAINER_NAME;
      unset $!CONTAINER_TAG;
      unset $!MESSAGE;
      unset $!_TRANSPORT;
      unset $!_PID;
      unset $!_UID;
      unset $!_GID;
      unset $!_COMM;
      unset $!_EXE;
      unset $!_CMDLINE;
      unset $!_CAP_EFFECTIVE;
      unset $!_SYSTEMD_CGROUP;
      unset $!_SYSTEMD_UNIT;
      unset $!_SYSTEMD_SLICE;
      unset $!_SELINUX_CONTEXT;
      unset $!_BOOT_ID;
      unset $!_MACHINE_ID;
      unset $!_HOSTNAME;
      unset $!_SOURCE_REALTIME_TIMESTAMP;

      action(type="omfwd" name="ext_log_endpoint" Template="ext-log-forwarding" Target="{{ ext_logging_endpoint }}" Port="514" Protocol="tcp"
        # Directory where the queue files on disk will be stored
        queue.spoolDirectory="/var/lib/rsyslog"
        # Prefix of the name the queue files on disk
        queue.filename="omfwd-queue"
        # In-memory linked-list queue, but because filename is defined it is disk-assisted
        # See http://www.rsyslog.com/doc/v8-stable/concepts/queues.html?highlight=disk%20assisted
        queue.type="linkedlist"
        # Only store up to 16 GB of logs on disk
        queue.maxdiskspace="16g"
        # Use 500 MB queue files
        queue.maxfilesize="500m"
        # Update disk queue every 1,000 messages
        queue.checkpointinterval="1000"
        # Fsync when a check point occurs
        queue.syncqueuefiles="on"
        # Allow up to 4 threads processing items in the queue
        queue.workerthreads="4"
        # Beef up the internal message queue
        queue.size="131072"
        # 75% of QueueSize, start persisting to disk
        queue.highwatermark="98304"
        # 90% of QueueSize, start discarding messages
        queue.discardmark="117964"
        # If we reach the discard mark, we'll throw out notice, info, and debug messages
        queue.discardseverity="5"
      )

      # Log to disk for debugging purposes only
      # action(type="omfile" Template="RSYSLOG_DebugFormat" File="/var/log/rsyslog-debug.log")
      stop
}
